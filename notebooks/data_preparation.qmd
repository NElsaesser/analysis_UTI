---
title: "Data Preparation for the Analysis of Ultrasound Tongue Imaging data"
author: 
  - name:
      given: 'Nathalie'
      family: 'Elsässer'
    affiliations:
      name: 'Acoustics Research Institute, <br> Austrian Academy of Sciences, Vienna'
    email: 'mailto:nathalie.elsaesser@oeaw.ac.at'
date: "2025-08-26"
output: html_document
format:
  html:
    theme: cosmo
    code-fold: true
    toc: true
    toc-location: left
    reference-location: margin
    df-print: kable
    embed-resources: true
    fig-cap-location: top
bibliography: references.bib
number-sections: true
---

# Libraries

```{r libraries, warning=FALSE, message=FALSE}
library(tidyverse)
library(rticulate)
library(plotly)
library(gridExtra)
source("polar_utils.R")
```


# Data preparation

The data is extracted from UTI recordings made in AAA. We have the data of 8 participants. The participants were prompted to read 319 target sentences -- each of those containing one /r/ in syllable onset position. The /r/s were annotated using Praat and afterwards, the annotations were imported to AAA to finally export the tongue splines within the /r/s.

The recording process was split in half: After reading half of the target sentences, each participant could decide to take a short break. During this break, the ultrasound probe was readjusted for some of the participants (e.g., because the probe slid down during the recording process). To account for the different probe positions within and between speakers, a so-called bite plane recording was done twice for each participant. Once before the first sentence, and a second time after the last recorded sentence. For the bite-plane recordings, the participants were prompted to take a small plastic plate into their mouth, bite on it and press their tongue against the plate. The flat tongue contour that was generated by this procedure got traced and used as a reference plane (the so-called "bite plane") afterwards.

The approximated tongue contours were created by an algorithm called DeepLabCut (DLC). DLC traced the tongue contours on each of the ultrasound images using 11 fixed points that lead to one "tongue spline" [@Wrench2022]. The 11 points are called "knots". The knots on the splines can be exported by AAA using Cartesian coordinates (x and y values). To account for individual differences between speakers and probe adjustments, the coordinates were adjusted in regards to the bite plane. They were offset in a way that made the most anterior point on the bite plane the new origin (x = 0, y = 0). Additionally, the data was rotated, so that the bite plane is exactly on the x-axis. This was done twice for each participant - once for the first half of the recordings, using the first recorded bite plane and once for the second half of the recordings, using the second bite plane.

The UTI data was sampled with a sampling rate of around 80 Hz, so there is one ultrasound image each \~12.5 ms. Since the rhotics have different lengths, each rhotic consists of a varying number of frames.

## cartesian coordinates

At first, we want to read in the output from AAA. Every participant has two tsv-files, one for the first and one for the second half of the target words. We will read these in and - since all of them have the same format - just rbind them together. We also want to give the individual knots specific labels (as in @Coretta2025).

```{r}
#| message: false
#| warning: false
#| echo: false

files = list.files(path = "../data/", pattern = "*.tsv")
data = list()
for (i in files) {
  file <- paste0("../data/", i)
  splines <- read_aaa(file)
  data[[i]] <- splines
  data[[i]]$filename <- strsplit(i,".",fixed = T)[[1]][1]
}
raw_data <- do.call(rbind, data)

knot_labels <- c("Vallecula","Root_1","Root_2","Body_1", "Body_2","Dorsum_1","Dorsum_2","Blade_1","Blade_2","Tip_1","Tip_2")
raw_data$knot_label <- rep(knot_labels,nrow(raw_data)/11)

raw_data$target <- str_split_i(raw_data$Prompt, " ", 2) # split Prompt -> target word alone
```

Since the column headers are very confusing, we change them:

```{r}
colnames(raw_data) <- c("participant", "sequence_no", "time_in_annot", "time_in_record", "date_time", "prompt", "annot_label", "knot", "spline", "x", "y", "frame_id", "displ_id", "filename", "knot_label", "target")
```

Get the frame_id together with the filename to avoid ggplot confusion when plotting the curves:

```{r}
raw_data$frame_id_file <- paste0(raw_data$filename, raw_data$frame_id)
```

Now we want to inspect the data. Does everything look alright?

```{r}
p <- raw_data |>
  ggplot(aes(x, y, group = frame_id_file, colour = filename)) +
  geom_point() +
  geom_path() +
  coord_fixed() +
  facet_wrap(vars(participant))

p
```

Most of the data looks good and as expected apart from a few spline fitting errors. But two participants seem to have a more general problem - 4 and 9. We want to take a closer look at that.

What's wrong with participant 4?

```{r}
p004 <- raw_data |>
  filter(participant == "vp004") |>
  ggplot(aes(x, y, group = frame_id_file, colour = filename, text = frame_id_file)) +
  geom_point() +
  geom_path() +
  coord_fixed() +
  facet_wrap(vars(participant))

# ggplotly(p004, tooltip = "text")
p004
```

We exclude the first half of VP004 (red in the plot above) because of spline fitting errors:

```{r}
raw_data <- raw_data %>% filter(filename != "vp004_1_bp1_knot1")
```

Now what about participant 9?

```{r}
p009 <- raw_data |>
  filter(participant == "vp009") |>
  ggplot(aes(x, y, group = frame_id_file, colour = filename, text = frame_id)) +
  geom_point() +
  geom_path() +
  coord_fixed() +
  facet_wrap(vars(participant))

# ggplotly(p009, tooltip = "text")
p009
```

In the second half, there seem to be too many spline fitting problems to exclude just some of them, so we exclude the entire 1st half. For the second half, we just exclude the prompts that are bad.

```{r}
prompt_excl <- c("Ohne Baumfrosch", "Bitte Chronologie", "Danke Brust", "Bitte Gruß", "Danke Anruf", "Danke Jura")
raw_data <- raw_data %>% filter(filename != "vp009_1_bp1_knot1" & !(prompt %in% prompt_excl))
```

We take a look at participant 9 again:
```{r}
p009 <- raw_data |>
  filter(participant == "vp009") |>
  ggplot(aes(x, y, group = frame_id_file, colour = filename, text = frame_id)) +
  geom_point() +
  geom_path() +
  coord_fixed() +
  facet_wrap(vars(participant))

# ggplotly(p009, tooltip = "text")
p009
```

There are also a few tracking errors that I found while looking through the other participants, they will get excluded here:

```{r}
prompt_excl10 <- c("Ohne Gratulation")
prompt_excl05 <- c("Ohne Kritik")
raw_data <- raw_data %>% filter(!(filename == "vp010_2_bp2_knot2" & prompt %in% prompt_excl10) | !(filename == "vp005_2_bp2_knot2" & prompt %in% prompt_excl05))
```


And at the whole data set:


```{r}
p <- raw_data |>
  ggplot(aes(x, y, group = frame_id_file, colour = filename)) +
  geom_point() +
  geom_path() +
  coord_fixed() +
  facet_wrap(vars(participant))

p
```

Looks good!

Now we create a variable to sort the data later:
```{r}
raw_data$sort_id  <- 1:nrow(raw_data)
```

### dynamic data

Next, we calculate the z-scores of the coordinate data. We normalize the data by `file` instead of by `participant` because we use two different biteplanes in the two halves of the recordings and want to minimize the influence of that.
```{r}
rhotic_data <- raw_data |> 
  mutate(
    filename = as.factor(filename)
  ) |> 
  group_by(filename) |> 
  mutate(
    x_z = (x - mean(x)) / sd(x),
    y_z = (y - mean(y)) / sd(y),
  ) |> 
  ungroup()
```

Let's plot this as well:
```{r}
p <- rhotic_data |>
  ggplot(aes(x_z, y_z, group = frame_id_file, colour = filename)) +
  geom_point() +
  geom_path() +
  coord_fixed() +
  facet_wrap(vars(participant))

p
```

And the both axes seperately:

```{r}
rhotic_data |>
  ggplot(aes(knot, x_z, group = frame_id_file, colour = filename)) +
  geom_path(alpha = 0.2) +
  facet_wrap(vars(participant), ncol = 4)
```

```{r}
rhotic_data |>
  ggplot(aes(knot, y_z, group = frame_id_file, colour = filename)) +
  geom_path(alpha = 0.2) +
  facet_wrap(vars(participant), ncol = 4)
```

Nice, that looks like it worked just fine :-)

We still need to normalize the time axis. There are different ways to do this -- for now, I decided that the first frame in each rhotic is at 0 \% of the `normtime`, the last frame is at 100 \%. If there are more than two frames, all the frames in between are equi-distant distributed over the rhotic (e.g., frame 2 of a rhotic containing 5 frames in total: (2-1)/(5-1) = 0.25, frame 3: (3-1)/(5-1) = 0.5 etc). If the rhotic consists of only one frame, the coordinates get labelled as both 0 \% and 100 \% of the normtime.

```{r}
rhotic_data <- rhotic_data %>% 
  group_by(filename, sequence_no) %>% 
  mutate(
    total = n_distinct(frame_id_file),
    rank = dense_rank(frame_id_file),
    normtime = ifelse(total == 1, 0, (rank - 1) / (total - 1) )
  ) %>% 
  ungroup() %>% 
  # also, we need a clip_id, what is basically a combination of filename and sequence_no
  mutate(clip_id = paste0(filename, "_", sequence_no)) 

rhotic_data <- rhotic_data %>% 
  # if there is only one time point in the /r/ (bc it's very short), we copy that so we have at least two time points in each rhotic (necessary for interpolation)
  rbind(rhotic_data %>% filter(total == 1) %>% mutate(normtime = 1,
                                                      frame_id_file = paste0(frame_id_file, "b"))) %>% 
  select(-total,-rank)
```

The data is now time-normalized, so that the first frame in an /r/ is at 0 %, the last frame is at 100 % and all frames between those two are equidistant.

Plot x- and y-coordinates with `normtime`:

```{r}
rhotic_data |>
  ggplot(aes(knot, x_z, group = frame_id_file, colour = normtime)) +
  geom_path(alpha = 0.2) +
  facet_wrap(vars(participant), ncol = 4)
```

```{r}
rhotic_data |>
  ggplot(aes(knot, y_z, group = frame_id_file, colour = normtime)) +
  geom_path(alpha = 0.2) +
  facet_wrap(vars(participant), ncol = 4)
```



Save data:
```{r}
saveRDS(rhotic_data, "../data/RDS/rhotic_data.rds")
```

### static data

We calculate the mean contour over all of the frames of one rhotic. Mean is calculated for each knot.

```{r}
rhotic_data_static <- rhotic_data %>%
  group_by(target, participant, filename, date_time, knot) %>% 
  summarize(
    x_mean = mean(x),
    y_mean = mean(y)
  ) %>% ungroup() %>% merge(
    rhotic_data %>% select(-c(sequence_no, time_in_annot, time_in_record, annot_label, spline, x, y, frame_id, displ_id, frame_id_file, sort_id, x_z, y_z, normtime)), by = c("participant", "target", "filename", "date_time", "knot")
  ) %>% unique()
rhotic_data_static <- rhotic_data_static[with(rhotic_data_static, order(participant, target, date_time, knot)), ]
rhotic_data_static$frame_id <- rep(1:(nrow(rhotic_data_static)/11), each=11)
```

Now, we have one tongue contour for each target word articulated by a participant that is the mean of all tongue contours in this /r/.

We check the data again to see if it worked. In the plot, the blue lines are the dynamic data and the red line is the mean that we calculated for one example word.

```{r}
rhotic_data %>% subset(participant == "vp008" & target == "Rand") |>
  ggplot(aes(x, y, group = frame_id_file, colour = normtime)) +
  coord_cartesian() +
  geom_path() +
  geom_path(data = rhotic_data_static %>% subset(participant == "vp008" & target == "Rand"), aes(x_mean, y_mean, group = frame_id), color = "red", lwd = 1.5) +
  facet_wrap(vars(participant))
```

It looks fine!

We also want to calculate z-scores for these mean coordinates:

```{r}
rhotic_data_static <- rhotic_data_static |> 
  group_by(filename) |> 
  mutate(
    x_mean_z = (x_mean - mean(x_mean)) / sd(x_mean),
    y_mean_z = (y_mean - mean(y_mean)) / sd(y_mean),
  ) |> 
  ungroup()
```

And make a plot of all of the data:

```{r}
p <- rhotic_data_static |>
  ggplot(aes(x_mean_z, y_mean_z, group = frame_id, colour = filename)) +
  geom_point() +
  geom_path() +
  coord_fixed() +
  facet_wrap(vars(participant))

p
```

Perfect!

Save data:
```{r}
saveRDS(rhotic_data_static, "../data/RDS/rhotic_data_static.rds")
```

## Polar coordinates

### The problem with Polar coordinates

As we also want to use polar instead of cartesian coordinates. For this purpose, we have to transform our data in some way. Problems arise because we have to choose one origin (= point where the radius is 0) for our data to create polar coordinates. Since the data of all of the participants was rotated at their individual biteplanes, it is nearly impossible to find one common point that makes a good origin for all 8 participants.

We look at our (non-z-scored) data again:

```{r}
p <- rhotic_data |>
  ggplot(aes(x, y, group = frame_id_file, colour = filename)) +
  geom_point() +
  geom_path() +
  coord_fixed() +
  facet_wrap(vars(participant))

p
```

When looking at participant 8 and e.g. participant 20, the problem becomes apparent: participant 8's data is way more fronted, their origin would probably best be something like (-20/-60), while participant 20's data would probably best have an origin at (-50/-60) or something.

If we just take one arbitrary origin via eye inspection, we could take (-40/-60) and see what it looks like:

```{r}
# convert to polar
origin <-  c(-40, -60) # eye inspection
polar_data <- rhotic_data %>% 
  cart2polar(origin, 'x', 'y')

print(head(polar_data))
```

```{r}
polar_plot <- ggplot(polar_data) +
  aes(angle, radius, group = frame_id_file, color = participant) +
  geom_path() +
  ggtitle("Raw polar coordinates using origin -40/-60") +
  radial_plot(100) +
  theme(legend.position = "bottom") 

polar_plot
```

The plots itself do not look bad but the differences between the participants are huge. If we calculated a FPCA with that data we would probably find a variation that describes the fact that some participants' tongue contours are further ahead than others in general, although we want to analyse the tongue shape and not their location within the coordinate system. I'm wondering if we could do some type of normalisation/z-score with this data as well?

### Cartesian z-scores to Polar - static

Another idea that I had was to take the z-scored Cartesian data, assign an origin to that and convert the z-scored data to polar:

```{r}
p <- rhotic_data_static |>
  ggplot(aes(x_mean_z, y_mean_z, group = frame_id, colour = filename)) +
  geom_point() +
  geom_path() +
  coord_fixed() +
  facet_wrap(vars(participant))

p
```

It looks like a good origin is around (0/-3).

```{r}
# convert to polar
origin <-  c(0, -3)
polar_data_static_z <- rhotic_data_static %>% 
  cart2polar(origin, 'x_mean_z', 'y_mean_z') %>% 
  select(-c("x_mean", "y_mean", "x_mean_z", "y_mean_z"))

print(head(polar_data_static_z))
```

```{r}
polar_plot_z <- ggplot(polar_data_static_z) +
  aes(angle, radius, group = frame_id, color = participant) +
  geom_path() +
  ggtitle("Polar coordinates calculated from the z-scored raw data; using origin (0/-3)") +
  radial_plot(5) +
  theme(legend.position = "bottom")
```

```{r}
polar_plot_z
```

It looks actually quite good.

```{r}
polar_plot_z_per_part <- ggplot(polar_data_static_z) +
    aes(angle, radius, group = frame_id, color = participant) +
    geom_path() +
    ggtitle("polar coordinates calculated from\nthe z-scored raw data; using origin 0/-3") +
    radial_plot(5) +
    theme(legend.position = "bottom") + facet_wrap(vars(participant), ncol = 3)
```

```{r}
polar_plot_z_per_part
```

I'm not entirely sure if this is a "good" way to transform the cartesian data to polar, especially because I chose the origin via eye inspection only and I'm not sure how I could to that more "objectively". But for the sake of trying out the stats models, I will use this data.

Save data:
```{r}
saveRDS(polar_data_static_z, "../data/RDS/rhotic_data_polar_static.rds")
```

### dynamic

Let's do the same thing with the dynamic data that we've already z-scored:

```{r}
# convert to polar
origin <-  c(0, -3)
polar_data_dyn_z <- rhotic_data %>% 
  cart2polar(origin, 'x_z', 'y_z') %>% 
  select(-c("x", "y", "x_z", "y_z"))
```

```{r}
polar_dyn_plot_z <- ggplot(polar_data_dyn_z) +
  aes(angle, radius, group = frame_id_file, color = participant) +
  geom_path() +
  ggtitle("polar coordinates calculated from the z-scored raw data; using origin 0/-3") +
  radial_plot(5) +
  theme(legend.position = "bottom")
```

```{r}
polar_dyn_plot_z
```

Save data:
```{r}
saveRDS(polar_data_dyn_z, "../data/RDS/rhotic_data_polar_dyn.rds")
```